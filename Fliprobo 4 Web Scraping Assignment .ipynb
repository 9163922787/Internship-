{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003d3584",
   "metadata": {},
   "source": [
    "Q1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859b707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f6164e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>video_name</th>\n",
       "      <th>uploader</th>\n",
       "      <th>Views in Billions</th>\n",
       "      <th>upload_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>9.90</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.68</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.06</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.57</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.37</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.79</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.54</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.48</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.41</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>4.37</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.29</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3.77</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.61</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.50</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.49</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.47</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.44</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.38</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.20</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.20</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.15</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.14</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.14</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.14</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.13</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.05</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>3.02</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.02</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.01</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                                 video_name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                               Shape of You   \n",
       "4    5.                              See You Again   \n",
       "5    6.                                  Bath Song   \n",
       "6    7.  Learning Colors – Colorful Eggs on a Farm   \n",
       "7    8.   Masha and the Bear – Recipe for Disaster   \n",
       "8    9.                                Uptown Funk   \n",
       "9   10.                Phonics Song with Two Words   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.                             Dame Tu Cosita   \n",
       "12  13.                                      Sugar   \n",
       "13  14.                                      Sorry   \n",
       "14  15.                                       Roar   \n",
       "15  16.                             Counting Stars   \n",
       "16  17.                          Wheels on the Bus   \n",
       "17  18.                          Thinking Out Loud   \n",
       "18  19.                             Girls Like You   \n",
       "19  20.                                      Faded   \n",
       "20  21.                                 Dark Horse   \n",
       "21  22.                                     Axel F   \n",
       "22  23.                                   Bailando   \n",
       "23  24.                                 Let Her Go   \n",
       "24  25.                                    Lean On   \n",
       "25  26.                               Shake It Off   \n",
       "26  27.                                    Perfect   \n",
       "27  28.                                   Mi Gente   \n",
       "28  29.           Waka Waka (This Time for Africa)   \n",
       "29  30.                        Baa Baa Black Sheep   \n",
       "\n",
       "                                       uploader Views in Billions  \\\n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories              9.90   \n",
       "1                                    Luis Fonsi              7.68   \n",
       "2                                   LooLoo Kids              6.06   \n",
       "3                                    Ed Sheeran              5.57   \n",
       "4                                   Wiz Khalifa              5.37   \n",
       "5                    Cocomelon – Nursery Rhymes              4.79   \n",
       "6                                   Miroshka TV              4.54   \n",
       "7                                    Get Movies              4.48   \n",
       "8                                   Mark Ronson              4.41   \n",
       "9                                     ChuChu TV              4.37   \n",
       "10                                          Psy              4.29   \n",
       "11                                    El Chombo              3.77   \n",
       "12                                     Maroon 5              3.61   \n",
       "13                                Justin Bieber              3.50   \n",
       "14                                   Katy Perry              3.49   \n",
       "15                                  OneRepublic              3.47   \n",
       "16                   Cocomelon – Nursery Rhymes              3.44   \n",
       "17                                   Ed Sheeran              3.38   \n",
       "18                                     Maroon 5              3.20   \n",
       "19                                  Alan Walker              3.20   \n",
       "20                                   Katy Perry              3.20   \n",
       "21                                   Crazy Frog              3.15   \n",
       "22                             Enrique Iglesias              3.14   \n",
       "23                                    Passenger              3.14   \n",
       "24                                  Major Lazer              3.14   \n",
       "25                                 Taylor Swift              3.13   \n",
       "26                                   Ed Sheeran              3.05   \n",
       "27                                     J Balvin              3.02   \n",
       "28                                      Shakira              3.02   \n",
       "29                   Cocomelon – Nursery Rhymes              3.01   \n",
       "\n",
       "          upload_date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3    January 30, 2017  \n",
       "4       April 6, 2015  \n",
       "5         May 2, 2018  \n",
       "6   February 27, 2018  \n",
       "7    January 31, 2012  \n",
       "8   November 19, 2014  \n",
       "9       March 6, 2014  \n",
       "10      July 15, 2012  \n",
       "11      April 5, 2018  \n",
       "12   January 14, 2015  \n",
       "13   October 22, 2015  \n",
       "14  September 5, 2013  \n",
       "15       May 31, 2013  \n",
       "16       May 24, 2018  \n",
       "17    October 7, 2014  \n",
       "18       May 31, 2018  \n",
       "19   December 3, 2015  \n",
       "20  February 20, 2014  \n",
       "21      June 16, 2009  \n",
       "22     April 11, 2014  \n",
       "23      July 25, 2012  \n",
       "24     March 22, 2015  \n",
       "25    August 18, 2014  \n",
       "26   November 9, 2017  \n",
       "27      June 29, 2017  \n",
       "28       June 4, 2010  \n",
       "29      June 25, 2018  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Firefox(executable_path=\"C:\\\\Users\\\\User\\\\geckodriver.exe\")\n",
    "#Loading url to the chrome driver\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(10)\n",
    "count = 0\n",
    "#creating list for rank, uploader)name, video name, no of views, date of upload\n",
    "rank = []\n",
    "video_names = []\n",
    "video_uploader_name = []\n",
    "views = []\n",
    "upload_dates = []\n",
    "\n",
    "\n",
    "    # Rank scraping\n",
    "try:\n",
    "    rank_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')[:30]\n",
    "    for i in rank_obj:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    rank.append('-')\n",
    "    \n",
    "    \n",
    "   #Name Scraping  \n",
    "try:\n",
    "    videoname_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')[:30]\n",
    "    for i in videoname_obj:\n",
    "        video_names.append(i.text.split('[')[0][1:-1])\n",
    "except NoSuchElementException :\n",
    "    video_names.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #uploader name scraping \n",
    "try:\n",
    "    uploader_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')[:30]\n",
    "    for i in uploader_obj:\n",
    "        video_uploader_name.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    video_uploader_name.append('-')\n",
    "    \n",
    "    \n",
    "\n",
    "    #View scraping \n",
    "try:\n",
    "    view_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')[:30]\n",
    "    for i in view_obj:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    views.append('-')\n",
    "    \n",
    "    \n",
    "    #Date of video scraping \n",
    "try:\n",
    "    date_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')[:30]\n",
    "    for i in date_obj:\n",
    "        upload_dates.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    upload_dates.append('-')\n",
    "\n",
    "# creating a diction of all the columns\n",
    "dict = {'rank':rank, 'video_name':video_names,'uploader':video_uploader_name,'Views in Billions':views,'upload_date':upload_dates}\n",
    "\n",
    "# Saving as Dataframe\n",
    "table = pd.DataFrame(dict)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0952941f",
   "metadata": {},
   "source": [
    "Q.2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5af39034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "url = 'https://www.bcci.tv/'\n",
    "driver.get(url)\n",
    "time.sleep(10)\n",
    "#Finding  the international fixture matches from the dropdown element\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "badfe8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "international_fixtures = driver.find_element_by_xpath(\"//div[@class='collapse navbar-collapse']//ul/li[2]/a\")\n",
    "\n",
    "international_fixtures.click()\n",
    "time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f33e8aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Series</th>\n",
       "      <th>Match</th>\n",
       "      <th>Match Location</th>\n",
       "      <th>series details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, Series, Match, Match Location, series details]\n",
       "Index: []"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "date = []\n",
    "\n",
    "time_note = []\n",
    "series = []\n",
    "place = []\n",
    "match_title = []\n",
    "match_details = []\n",
    "\n",
    "# MERging Month and Day together for Date OBject\n",
    "try :\n",
    "    month_obj = driver.find_elements_by_xpath('//span[@class=\"fixture__month\"]')\n",
    "    day_obj = driver.find_elements_by_xpath('//span[@class=\"fixture__date\"]')\n",
    "    for i in range(len(month_obj)):\n",
    "        date.append(str(day_obj[i].text)+'-'+str(month_obj[i].text).lower())\n",
    "except NoSuchElementException:\n",
    "    date.append('-')\n",
    "    \n",
    "    \n",
    "# Time of match  \n",
    "\n",
    "try :\n",
    "    time_obj = driver.find_elements_by_xpath('//span[@class=\"fixture__time\"]')\n",
    "    \n",
    "    for i in range(len(time_obj)):\n",
    "        time_note.append(str(time_obj[i].text))\n",
    "except NoSuchElementException:\n",
    "    time_note.append('-')\n",
    "\n",
    "    \n",
    "#series details and Match Tittle\n",
    "\n",
    "try :\n",
    "    series_obj = driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__format\"]')\n",
    "    title_obj = driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__tournament-label u-truncated\"]')\n",
    "    for i in range(len(month_obj)):\n",
    "        series.append(str(series_obj[i].text)+' '+str(title_obj[i].text))\n",
    "        match_title.append(str(title_obj[i].text))\n",
    "except NoSuchElementException:\n",
    "    series.append('-')\n",
    "\n",
    "    \n",
    "# Location of MAtch, and series information\n",
    "\n",
    "try :\n",
    "    location_obj = driver.find_elements_by_xpath('//p[@class=\"fixture__additional-info\"]/span')\n",
    "    match_name_obj = driver.find_elements_by_xpath('//strong[@class=\"fixture__name fixture__name--with-margin\"]')\n",
    "    for i in range(len(time_obj)):\n",
    "        place.append(str(location_obj[i].text))\n",
    "        match_details.append(match_name_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    place.append ('-')\n",
    "\n",
    "#time.sleep(5)\n",
    "#creating the dictionary of the elements\n",
    "dict= {\n",
    "    'Date':date,'Time':time_note,'Series':series,'Match': match_title,'Match Location':place,\n",
    "    'series details': match_details\n",
    "}\n",
    "\n",
    "#creating with creating a DataFrame\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "132df310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Match Title, Series, Place, Date, Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "# Let's activate and load the chrome browser\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Let's open the URL\n",
    "driver.get('https://www.bcci.tv/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's navigate to the international fixtures page\n",
    "international_fixture=driver.find_element_by_xpath(\"//div[@class='collapse navbar-collapse']//ul/li[2]/a\")\n",
    "driver.get(international_fixture.get_attribute('href'))\n",
    "time.sleep(10)\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Match_title=[] \n",
    "Series=[]\n",
    "Place=[] \n",
    "Date=[] \n",
    "Time=[]\n",
    "\n",
    "# Let's create a function to get the Match details\n",
    "title = driver.find_elements_by_xpath('//strong[@class=\"fixture__name fixture__name--with-margin\"]')\n",
    "for i in title:\n",
    "    Match_title.append(i.text)\n",
    "series = driver.find_elements_by_xpath('//div[@class=\"fixture__format-strip\"]/span[2]')\n",
    "for i in series:\n",
    "    Series.append(i.text)\n",
    "place = driver.find_elements_by_xpath('//p[@class=\"fixture__additional-info\"]/span')\n",
    "for i in place:\n",
    "    Place.append(i.text)\n",
    "date = driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]/div/span')\n",
    "month = driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]/div/div/span[1]')\n",
    "for i in range(len(date)):\n",
    "    Date.append(date[i].text+month[i].text)\n",
    "time = driver.find_elements_by_xpath('//div[@class=\"fixture__full-date\"]/div/span[2]')\n",
    "for i in time:\n",
    "    Time.append(i.text)\n",
    "    \n",
    "# Let's create the dataframe from the scraped data\n",
    "IF_ICC=pd.DataFrame({})\n",
    "IF_ICC['Match Title']=Match_title\n",
    "IF_ICC['Series']=Series\n",
    "IF_ICC['Place']=Place \n",
    "IF_ICC['Date']=Date\n",
    "IF_ICC['Time']=Time\n",
    "IF_ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "446e5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8095744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd503cb",
   "metadata": {},
   "source": [
    "Q3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0dbb75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can’t be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n’t sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception Name  \\\n",
       "0         ElementNotSelectableException   \n",
       "1                NoSuchElementException   \n",
       "2                  NoSuchFrameException   \n",
       "3               NoAlertPresentException   \n",
       "4                 NoSuchWindowException   \n",
       "5        StaleElementReferenceException   \n",
       "6              SessionNotFoundException   \n",
       "7                      TimeoutException   \n",
       "8                    WebDriverException   \n",
       "9             ConnectionClosedException   \n",
       "10     ElementClickInterceptedException   \n",
       "11      ElementNotInteractableException   \n",
       "12             ErrorInResponseException   \n",
       "13  ErrorHandler.UnknownServerException   \n",
       "14         ImeActivationFailedException   \n",
       "15             ImeNotAvailableException   \n",
       "16         InsecureCertificateException   \n",
       "17             InvalidArgumentException   \n",
       "18         InvalidCookieDomainException   \n",
       "19          InvalidCoordinatesException   \n",
       "20          InvalidElementStateExceptio   \n",
       "21            InvalidSessionIdException   \n",
       "22       InvalidSwitchToTargetException   \n",
       "23                  JavascriptException   \n",
       "24                        JsonException   \n",
       "25             NoSuchAttributeException   \n",
       "26       MoveTargetOutOfBoundsException   \n",
       "27               NoSuchContextException   \n",
       "28                NoSuchCookieException   \n",
       "29                    NotFoundException   \n",
       "30          RemoteDriverServerException   \n",
       "31                  ScreenshotException   \n",
       "32           SessionNotCreatedException   \n",
       "33           UnableToSetCookieException   \n",
       "34           UnexpectedTagNameException   \n",
       "35              UnhandledAlertException   \n",
       "36      UnexpectedAlertPresentException   \n",
       "37               UnknownMethodException   \n",
       "38          UnreachableBrowserException   \n",
       "39          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This Selenium exception occurs when an element...  \n",
       "1   This Exception occurs if an element could not ...  \n",
       "2   This Exception occurs if the frame target to b...  \n",
       "3   This Exception occurs when you switch to no pr...  \n",
       "4   This Exception occurs if the window target to ...  \n",
       "5   This Selenium exception occurs happens when th...  \n",
       "6   The WebDriver is acting after you quit the bro...  \n",
       "7   Thrown when there is not enough time for a com...  \n",
       "8   This Exception takes place when the WebDriver ...  \n",
       "9   This type of Exception takes place when there ...  \n",
       "10  The command may not be completed as the elemen...  \n",
       "11  This Selenium exception is thrown when any ele...  \n",
       "12  This happens while interacting with the Firefo...  \n",
       "13  Exception is used as a placeholder in case if ...  \n",
       "14  This expectation will occur when IME engine ac...  \n",
       "15    It takes place when IME support is unavailable.  \n",
       "16  Navigation made the user agent to hit a certif...  \n",
       "17  It occurs when an argument does not belong to ...  \n",
       "18  This happens when you try to add a cookie unde...  \n",
       "19  This type of Exception matches an interacting ...  \n",
       "20  It occurs when command can’t be finished when ...  \n",
       "21  This Exception took place when the given sessi...  \n",
       "22  This occurs when the frame or window target to...  \n",
       "23  This issue occurs while executing JavaScript g...  \n",
       "24  It occurs when you afford to get the session w...  \n",
       "25  This kind of Exception occurs when the attribu...  \n",
       "26  It takes place if the target provided to the A...  \n",
       "27           ContextAware does mobile device testing.  \n",
       "28  This Exception occurs when no cookie matching ...  \n",
       "29  This Exception is a subclass of WebDriverExcep...  \n",
       "30  This Selenium exception is thrown when the ser...  \n",
       "31            It is not possible to capture a screen.  \n",
       "32  It happens when a new session could not be suc...  \n",
       "33  This occurs if a driver is unable to set a coo...  \n",
       "34  Happens if a support class did not get a web e...  \n",
       "35  This expectation occurs when there is an alert...  \n",
       "36  It occurs when there is the appearance of an u...  \n",
       "37  This Exception happens when the requested comm...  \n",
       "38  This Exception occurs only when the browser is...  \n",
       "39  This occurs when remote WebDriver does n’t sen...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Firefox(executable_path=\"C:\\\\Users\\\\User\\\\geckodriver.exe\")\n",
    "\n",
    "# Let's open the URL\n",
    "driver.get('https://www.guru99.com/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's click on the selenium exception page \n",
    "driver.find_element_by_xpath(\"//div[@class='srch']/span[8]/a\").click()\n",
    "\n",
    "# Let's click on the selenium exception tutorial link\n",
    "driver.find_element_by_xpath(\"//table[@class='table']/tbody/tr[34]/td/a\").click()\n",
    "\n",
    "\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Name=[]\n",
    "Description=[]\n",
    "\n",
    "# Let's create a function\n",
    "try:\n",
    "    name = driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[1]')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    print(\"could not find Name xpath\")\n",
    "\n",
    "try:\n",
    "    description = driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[2]')\n",
    "    for i in description:\n",
    "        Description.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    print(\"Could not find description xpath\")\n",
    "# Let's create the dataframe from the scraped data\n",
    "guru99=pd.DataFrame({})\n",
    "guru99['Exception Name']=Name[1:]\n",
    "guru99['Description']=Description[1:]\n",
    "guru99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29273c3e",
   "metadata": {},
   "source": [
    "Q4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP\n",
    "D) GSDP\n",
    "E) Share\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4c80f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP (Cr INR at Current prices) Year 2018-2019</th>\n",
       "      <th>GSDP (Cr INR at Current prices) Year 2019-2020</th>\n",
       "      <th>Share Year 2018-2019</th>\n",
       "      <th>GDP ($ Billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State  \\\n",
       "0     1                Maharashtra   \n",
       "1     2                 Tamil Nadu   \n",
       "2     3              Uttar Pradesh   \n",
       "3     4                    Gujarat   \n",
       "4     5                  Karnataka   \n",
       "5     6                West Bengal   \n",
       "6     7                  Rajasthan   \n",
       "7     8             Andhra Pradesh   \n",
       "8     9                  Telangana   \n",
       "9    10             Madhya Pradesh   \n",
       "10   11                     Kerala   \n",
       "11   12                      Delhi   \n",
       "12   13                    Haryana   \n",
       "13   14                      Bihar   \n",
       "14   15                     Punjab   \n",
       "15   16                     Odisha   \n",
       "16   17                      Assam   \n",
       "17   18               Chhattisgarh   \n",
       "18   19                  Jharkhand   \n",
       "19   20                Uttarakhand   \n",
       "20   21            Jammu & Kashmir   \n",
       "21   22           Himachal Pradesh   \n",
       "22   23                        Goa   \n",
       "23   24                    Tripura   \n",
       "24   25                 Chandigarh   \n",
       "25   26                 Puducherry   \n",
       "26   27                  Meghalaya   \n",
       "27   28                     Sikkim   \n",
       "28   29                    Manipur   \n",
       "29   30                   Nagaland   \n",
       "30   31          Arunachal Pradesh   \n",
       "31   32                    Mizoram   \n",
       "32   33  Andaman & Nicobar Islands   \n",
       "\n",
       "   GSDP (Cr INR at Current prices) Year 2018-2019  \\\n",
       "0                                       2,632,792   \n",
       "1                                       1,630,208   \n",
       "2                                       1,584,764   \n",
       "3                                       1,502,899   \n",
       "4                                       1,493,127   \n",
       "5                                       1,089,898   \n",
       "6                                         942,586   \n",
       "7                                         862,957   \n",
       "8                                         861,031   \n",
       "9                                         809,592   \n",
       "10                                        781,653   \n",
       "11                                        774,870   \n",
       "12                                        734,163   \n",
       "13                                        530,363   \n",
       "14                                        526,376   \n",
       "15                                        487,805   \n",
       "16                                        315,881   \n",
       "17                                        304,063   \n",
       "18                                        297,204   \n",
       "19                                        245,895   \n",
       "20                                        155,956   \n",
       "21                                        153,845   \n",
       "22                                         73,170   \n",
       "23                                         49,845   \n",
       "24                                         42,114   \n",
       "25                                         34,433   \n",
       "26                                         33,481   \n",
       "27                                         28,723   \n",
       "28                                         27,870   \n",
       "29                                         27,283   \n",
       "30                                         24,603   \n",
       "31                                         22,287   \n",
       "32                                              -   \n",
       "\n",
       "   GSDP (Cr INR at Current prices) Year 2019-2020 Share Year 2018-2019  \\\n",
       "0                                               -               13.94%   \n",
       "1                                       1,845,853                8.63%   \n",
       "2                                       1,687,818                8.39%   \n",
       "3                                               -                7.96%   \n",
       "4                                       1,631,977                7.91%   \n",
       "5                                       1,253,832                5.77%   \n",
       "6                                       1,020,989                4.99%   \n",
       "7                                         972,782                4.57%   \n",
       "8                                         969,604                4.56%   \n",
       "9                                         906,672                4.29%   \n",
       "10                                              -                4.14%   \n",
       "11                                        856,112                4.10%   \n",
       "12                                        831,610                3.89%   \n",
       "13                                        611,804                2.81%   \n",
       "14                                        574,760                2.79%   \n",
       "15                                        521,275                2.58%   \n",
       "16                                              -                1.67%   \n",
       "17                                        329,180                1.61%   \n",
       "18                                        328,598                1.57%   \n",
       "19                                              -                1.30%   \n",
       "20                                              -                0.83%   \n",
       "21                                        165,472                0.81%   \n",
       "22                                         80,449                0.39%   \n",
       "23                                         55,984                0.26%   \n",
       "24                                              -                0.22%   \n",
       "25                                         38,253                0.18%   \n",
       "26                                         36,572                0.18%   \n",
       "27                                         32,496                0.15%   \n",
       "28                                         31,790                0.15%   \n",
       "29                                              -                0.14%   \n",
       "30                                              -                0.13%   \n",
       "31                                         26,503                0.12%   \n",
       "32                                              -                    -   \n",
       "\n",
       "   GDP ($ Billion)  \n",
       "0          399.921  \n",
       "1          247.629  \n",
       "2          240.726  \n",
       "3          228.290  \n",
       "4          226.806  \n",
       "5          165.556  \n",
       "6          143.179  \n",
       "7          131.083  \n",
       "8          130.791  \n",
       "9          122.977  \n",
       "10         118.733  \n",
       "11         117.703  \n",
       "12         111.519  \n",
       "13          80.562  \n",
       "14          79.957  \n",
       "15          74.098  \n",
       "16          47.982  \n",
       "17          46.187  \n",
       "18          45.145  \n",
       "19          37.351  \n",
       "20          23.690  \n",
       "21          23.369  \n",
       "22          11.115  \n",
       "23           7.571  \n",
       "24           6.397  \n",
       "25           5.230  \n",
       "26           5.086  \n",
       "27           4.363  \n",
       "28           4.233  \n",
       "29           4.144  \n",
       "30           3.737  \n",
       "31           3.385  \n",
       "32               -  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Let's open the URL\n",
    "driver.get('http://statisticstimes.com/')\n",
    "driver.implicitly_wait(3)\n",
    "Economy_India=driver.find_element_by_xpath(\"//div[@class='navbar']/div[2]/button\")\n",
    "Economy_India.click()\n",
    "india=driver.find_element_by_xpath(\"//div[@class='navbar']/div[2]/div/a[3]\")\n",
    "india.click()\n",
    "#\"ns-mv5la-e-14 button-common close-button\"\n",
    "#add_close=driver.find_element_by_xpath(\"//div[@class='ns-mv5la-e-14 button-common close-button']\")\n",
    "#add_close.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Let's click on the GDP of Indian states \n",
    "GDP_Indian_States=driver.find_element_by_xpath(\"//div[@style='float:left;background-color:seashell;width:400px;height:800px;']/ul/li[1]/a\")\n",
    "driver.get(GDP_Indian_States.get_attribute('href'))\n",
    "time.sleep(5)\n",
    "\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Rank=[] \n",
    "State=[] \n",
    "GSDP_Year_2019_to_Year_2020=[] \n",
    "GSDP_Year_2018_to_Year_2019=[] \n",
    "Share_Year_2018_to_2019=[] \n",
    "GDP_Dollar_Billion=[]\n",
    "\n",
    "# scrape the data \n",
    "rank = driver.find_elements_by_xpath('//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "try:    \n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "    state = driver.find_elements_by_xpath('//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "except NoSuchElementException:\n",
    "    Rank.append('-')\n",
    "try:\n",
    "    for i in state:\n",
    "        State.append(i.text)\n",
    "    gdsp_19_20 = driver.find_elements_by_xpath('//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "except NoSuchElementException:\n",
    "    State.append('-')\n",
    "\n",
    "try:\n",
    "    for i in gdsp_19_20:\n",
    "        GSDP_Year_2019_to_Year_2020.append(i.text)\n",
    "    gdsp_18_19 = driver.find_elements_by_xpath('//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "except NoSuchElementException:\n",
    "    GSDP_Year_2019_to_Year_2020.append('-')\n",
    "\n",
    "try:\n",
    "    for i in gdsp_18_19:\n",
    "        GSDP_Year_2018_to_Year_2019.append(i.text)\n",
    "    share = driver.find_elements_by_xpath('//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "except NoSuchElementException:\n",
    "    GSDP_Year_2018_to_Year_2019.append('-')\n",
    "\n",
    "try:\n",
    "    for i in share:\n",
    "        Share_Year_2018_to_2019.append(i.text)\n",
    "    gdp_dollar = driver.find_elements_by_xpath('//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "except NoSuchElementException:\n",
    "    Share_Year_2018_to_2019.append('-')\n",
    "\n",
    "try:\n",
    "    for i in gdp_dollar:\n",
    "        GDP_Dollar_Billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_Dollar_Billion.append('-')\n",
    "\n",
    "# Let's create the dataframe from the scraped data\n",
    "GSDP=pd.DataFrame({})\n",
    "GSDP['Rank']=Rank \n",
    "GSDP['State']=State\n",
    "GSDP['GSDP (Cr INR at Current prices) Year 2018-2019']=GSDP_Year_2018_to_Year_2019 \n",
    "GSDP['GSDP (Cr INR at Current prices) Year 2019-2020']=GSDP_Year_2019_to_Year_2020 \n",
    "GSDP['Share Year 2018-2019']=Share_Year_2018_to_2019 \n",
    "GSDP['GDP ($ Billion)']=GDP_Dollar_Billion\n",
    "GSDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f2c73",
   "metadata": {},
   "source": [
    "Q5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8d0163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mkrl / misbrands</td>\n",
       "      <td>The world's most hated IT stickers</td>\n",
       "      <td>-</td>\n",
       "      <td>[The, most, IT, Resources, License, License, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>babysor / MockingBird</td>\n",
       "      <td>🚀AI拟声: 5秒内克隆您的声音并生成任意语音内容 Clone a voice in 5 s...</td>\n",
       "      <td>19</td>\n",
       "      <td>[JavaScript, Python, HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mpcabete / bombcrypto-bot</td>\n",
       "      <td>This is a python bot that automatically logs i...</td>\n",
       "      <td>9</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TeamNewPipe / NewPipe</td>\n",
       "      <td>A libre lightweight streaming front-end for An...</td>\n",
       "      <td>636</td>\n",
       "      <td>[Java, Kotlin, HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marktext / marktext</td>\n",
       "      <td>📝A simple and elegant markdown editor, availab...</td>\n",
       "      <td>118</td>\n",
       "      <td>[JavaScript, Vue, CSS, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>donnemartin / system-design-primer</td>\n",
       "      <td>Learn how to design large-scale systems. Prep ...</td>\n",
       "      <td>111</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zeldaret / oot</td>\n",
       "      <td>Decompilation of The Legend of Zelda: Ocarina ...</td>\n",
       "      <td>65</td>\n",
       "      <td>[C, C++, Python, Assembly, Makefile, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>airbnb / javascript</td>\n",
       "      <td>JavaScript Style Guide</td>\n",
       "      <td>481</td>\n",
       "      <td>[JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>teslamotors / light-show</td>\n",
       "      <td>Tesla Light Show</td>\n",
       "      <td>2</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alesimula / wsa_pacman</td>\n",
       "      <td>A GUI package manager and package installer fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Dart, C++, CMake, Inno, 1.8%, 0.5%]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Courseplay / Courseplay_FS22</td>\n",
       "      <td>Courseplay for Farming Simulator 2022</td>\n",
       "      <td>15</td>\n",
       "      <td>[Lua, Batchfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cisagov / log4j-scanner</td>\n",
       "      <td>log4j-scanner is a project derived from other ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Java, Python, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dair-ai / ML-YouTube-Courses</td>\n",
       "      <td>A repository to index and organize the latest ...</td>\n",
       "      <td>-</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R2Northstar / Northstar</td>\n",
       "      <td>Repo for packaged Northstar releases and the wiki</td>\n",
       "      <td>6</td>\n",
       "      <td>[No, published]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bitcoin / bitcoin</td>\n",
       "      <td>Bitcoin Core integration/staging tree</td>\n",
       "      <td>847</td>\n",
       "      <td>[C++, Python, C, M4, Shell, Makefile, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>R2Northstar / NorthstarMods</td>\n",
       "      <td>Mods used for hosting Titanfall 2 custom serve...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Squirrel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>trekhleb / javascript-algorithms</td>\n",
       "      <td>📝 Algorithms and data structures implemented i...</td>\n",
       "      <td>143</td>\n",
       "      <td>[JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gto76 / python-cheatsheet</td>\n",
       "      <td>Comprehensive Python Cheatsheet</td>\n",
       "      <td>11</td>\n",
       "      <td>[Python, JavaScript, HTML, CSS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>freeCodeCamp / LearnToCodeRPG</td>\n",
       "      <td>A visual novel video game where you learn to c...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Ren'Py, HTML, CSS, JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sindresorhus / awesome</td>\n",
       "      <td>😎 Awesome lists about all kinds of interesting...</td>\n",
       "      <td>-</td>\n",
       "      <td>[512, 501]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mtdvio / every-programmer-should-know</td>\n",
       "      <td>A collection of (mostly) technical things ever...</td>\n",
       "      <td>-</td>\n",
       "      <td>[71, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30-seconds / 30-seconds-of-code</td>\n",
       "      <td>Short JavaScript code snippets for all your de...</td>\n",
       "      <td>264</td>\n",
       "      <td>[JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>awesome-selfhosted / awesome-selfhosted</td>\n",
       "      <td>A list of Free Software network services and w...</td>\n",
       "      <td>979</td>\n",
       "      <td>[JavaScript, Makefile, Python, Ruby]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JustArchiNET / ArchiSteamFarm</td>\n",
       "      <td>C# application with primary purpose of idling ...</td>\n",
       "      <td>34</td>\n",
       "      <td>[C#, C++, Shell, Other]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Repository Title  \\\n",
       "0                          mkrl / misbrands   \n",
       "1                     babysor / MockingBird   \n",
       "2                 mpcabete / bombcrypto-bot   \n",
       "3                     TeamNewPipe / NewPipe   \n",
       "4                       marktext / marktext   \n",
       "5        donnemartin / system-design-primer   \n",
       "6                            zeldaret / oot   \n",
       "7                       airbnb / javascript   \n",
       "8                  teslamotors / light-show   \n",
       "9                    alesimula / wsa_pacman   \n",
       "10             Courseplay / Courseplay_FS22   \n",
       "11                  cisagov / log4j-scanner   \n",
       "12             dair-ai / ML-YouTube-Courses   \n",
       "13                  R2Northstar / Northstar   \n",
       "14                        bitcoin / bitcoin   \n",
       "15              R2Northstar / NorthstarMods   \n",
       "16         trekhleb / javascript-algorithms   \n",
       "17                gto76 / python-cheatsheet   \n",
       "18            freeCodeCamp / LearnToCodeRPG   \n",
       "19                   sindresorhus / awesome   \n",
       "20    mtdvio / every-programmer-should-know   \n",
       "21          30-seconds / 30-seconds-of-code   \n",
       "22  awesome-selfhosted / awesome-selfhosted   \n",
       "23            JustArchiNET / ArchiSteamFarm   \n",
       "\n",
       "                               Repository Description Contributors Count  \\\n",
       "0                  The world's most hated IT stickers                  -   \n",
       "1   🚀AI拟声: 5秒内克隆您的声音并生成任意语音内容 Clone a voice in 5 s...                 19   \n",
       "2   This is a python bot that automatically logs i...                  9   \n",
       "3   A libre lightweight streaming front-end for An...                636   \n",
       "4   📝A simple and elegant markdown editor, availab...                118   \n",
       "5   Learn how to design large-scale systems. Prep ...                111   \n",
       "6   Decompilation of The Legend of Zelda: Ocarina ...                 65   \n",
       "7                              JavaScript Style Guide                481   \n",
       "8                                    Tesla Light Show                  2   \n",
       "9   A GUI package manager and package installer fo...                  2   \n",
       "10              Courseplay for Farming Simulator 2022                 15   \n",
       "11  log4j-scanner is a project derived from other ...                  4   \n",
       "12  A repository to index and organize the latest ...                  -   \n",
       "13  Repo for packaged Northstar releases and the wiki                  6   \n",
       "14              Bitcoin Core integration/staging tree                847   \n",
       "15  Mods used for hosting Titanfall 2 custom serve...                  -   \n",
       "16  📝 Algorithms and data structures implemented i...                143   \n",
       "17                    Comprehensive Python Cheatsheet                 11   \n",
       "18  A visual novel video game where you learn to c...                  6   \n",
       "19  😎 Awesome lists about all kinds of interesting...                  -   \n",
       "20  A collection of (mostly) technical things ever...                  -   \n",
       "21  Short JavaScript code snippets for all your de...                264   \n",
       "22  A list of Free Software network services and w...                979   \n",
       "23  C# application with primary purpose of idling ...                 34   \n",
       "\n",
       "                                        Language Used  \n",
       "0   [The, most, IT, Resources, License, License, 4...  \n",
       "1                          [JavaScript, Python, HTML]  \n",
       "2                                            [Python]  \n",
       "3                                [Java, Kotlin, HTML]  \n",
       "4                       [JavaScript, Vue, CSS, Other]  \n",
       "5                                     [Python, Shell]  \n",
       "6         [C, C++, Python, Assembly, Makefile, Shell]  \n",
       "7                                        [JavaScript]  \n",
       "8                                            [Python]  \n",
       "9                [Dart, C++, CMake, Inno, 1.8%, 0.5%]  \n",
       "10                                   [Lua, Batchfile]  \n",
       "11                         [Java, Python, Dockerfile]  \n",
       "12                                                [2]  \n",
       "13                                    [No, published]  \n",
       "14       [C++, Python, C, M4, Shell, Makefile, Other]  \n",
       "15                                         [Squirrel]  \n",
       "16                                       [JavaScript]  \n",
       "17                    [Python, JavaScript, HTML, CSS]  \n",
       "18                    [Ren'Py, HTML, CSS, JavaScript]  \n",
       "19                                         [512, 501]  \n",
       "20                                           [71, 60]  \n",
       "21                                       [JavaScript]  \n",
       "22               [JavaScript, Makefile, Python, Ruby]  \n",
       "23                            [C#, C++, Shell, Other]  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "# Let's activate and load the chrome browser\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Let's define the url\n",
    "url=('https://github.com/')\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "try:\n",
    "    link_trending = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a').get_attribute('href')\n",
    "except NoSuchElementException:\n",
    "    print(\"Trending xpath could not be found\")\n",
    "\n",
    "driver.get(link_trending)\n",
    "time.sleep(5)\n",
    "# Let's create an empty lists to store scraping data\n",
    "Repository_Title=[]\n",
    "Repository_Description=[] \n",
    "Contributors_Count=[] \n",
    "Language_Used=[]\n",
    "urls=[]\n",
    "\n",
    "# Let's create a function\n",
    "try:\n",
    "    rep_title=driver.find_elements_by_xpath('//article[@class=\"Box-row\"]/h1/a')\n",
    "except NoSuchElementException:\n",
    "    print(\"Title xpath could not be found\")\n",
    "try:\n",
    "    descriptions=driver.find_elements_by_xpath('//article[@class=\"Box-row\"]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Description xpath could not be found\")\n",
    "\n",
    "for i in [rep_title,descriptions]:\n",
    "    for j in i:\n",
    "        if i ==rep_title:\n",
    "            Repository_Title.append(j.text)\n",
    "            urls.append(j.get_attribute('href'))\n",
    "        if i==descriptions:\n",
    "            Repository_Description.append(j.text)\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    div_list=driver.find_elements_by_xpath('//div[@class=\"BorderGrid BorderGrid--spacious\"]/div')\n",
    "    try:\n",
    "        Contributors_Count.append(((div_list[-2].text).split())[1])\n",
    "    except:\n",
    "        Contributors_Count.append('-')\n",
    "    try:\n",
    "        Language_Used.append(((div_list[-1].text).split())[1::2])\n",
    "    except:\n",
    "        Language_Used.append('-')\n",
    "\n",
    "# Let's check the length of the scrape data        \n",
    "print(len(Repository_Title),len(Repository_Description),len(Contributors_Count),len(Language_Used))\n",
    "\n",
    "\n",
    "# L3t's create the dataframe from the scraped data\n",
    "Repositoriy=pd.DataFrame({})\n",
    "Repositoriy['Repository Title']=Repository_Title[0:24]\n",
    "Repositoriy['Repository Description']=Repository_Description[0:24]\n",
    "Repositoriy['Contributors Count']=Contributors_Count[0:24]\n",
    "Repositoriy['Language Used']=Language_Used[0:24]\n",
    "Repositoriy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510af15",
   "metadata": {},
   "source": [
    "Q.Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "755313e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Song_name, Artist_name, Last_week_rank, Peak_rank, Weeks_on_board]\n",
       "Index: []"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "# Let's activate and load the chrome browser\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Let's open the URL\n",
    "driver.get('https://www.billboard.com/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's navigate and click on the Top 100 Songs\n",
    "link=driver.find_element_by_xpath(\"//a[@href='/charts/hot-100']\").get_attribute('href')\n",
    "\n",
    "\n",
    "\n",
    "#loading the extracted link of the hot top 100\n",
    "driver.get(link)\n",
    "\n",
    "\n",
    "time.sleep(10)\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Song_Name=[]\n",
    "Artist_Name=[] \n",
    "Last_Week_Rank=[] \n",
    "Peak_Rank=[]\n",
    "Weeks_on_Board=[]\n",
    "\n",
    "# Let's create a function\n",
    "song = driver.find_elements_by_xpath('//span[@class=\"chart-element__information__song text--truncate color--primary\"]')\n",
    "for i in song:\n",
    "    Song_Name.append(i.text)\n",
    "artist = driver.find_elements_by_xpath('//span[@class=\"chart-element__information__artist text--truncate color--secondary\"]')\n",
    "for i in artist:\n",
    "    Artist_Name.append(i.text)\n",
    "lastweek = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]')\n",
    "for i in lastweek:\n",
    "    Last_Week_Rank.append(i.text)\n",
    "peak = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]')\n",
    "for i in peak:\n",
    "    Peak_Rank.append(i.text)\n",
    "weeks = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]')\n",
    "for i in weeks:\n",
    "    Weeks_on_Board.append(i.text)\n",
    "    \n",
    "# Let's create the dataframe from the scraped data\n",
    "TOP_100_SONGS=pd.DataFrame({})\n",
    "TOP_100_SONGS['Song_name']=Song_Name\n",
    "TOP_100_SONGS['Artist_name']=Artist_Name\n",
    "TOP_100_SONGS['Last_week_rank']=Last_Week_Rank\n",
    "TOP_100_SONGS['Peak_rank']=Peak_Rank\n",
    "TOP_100_SONGS['Weeks_on_board']= Weeks_on_Board\n",
    "TOP_100_SONGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b7210",
   "metadata": {},
   "source": [
    "Q7.Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce0eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Let's activate and load the chrome browser\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Let's open the URL\n",
    "driver.get('https://www.naukri.com/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's navigate and clciking on the recruiter option on the search pane\n",
    "recruiter=driver.find_element_by_xpath(\"//ul[@class='midSec menu']/li[2]/a\")\n",
    "driver.get(recruiter.get_attribute('href'))\n",
    "time.sleep(5)\n",
    "# Let's navigate to the search bar and Type Data Science in the search bar and click search\n",
    "search_field_designation=driver.find_element_by_xpath(\"//input[@class='sugInp']\")\n",
    "search_field_designation.send_keys(\"Data Science\")\n",
    "driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\").click()\n",
    "time.sleep(5)\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Name=[]\n",
    "Designation=[] \n",
    "Company=[] \n",
    "Skills_they_hire_for=[] \n",
    "Location=[]\n",
    "\n",
    "# Scrape the data as metioned in question\n",
    "try:\n",
    "    name = driver.find_elements_by_xpath('//span[@class=\"fl ellipsis\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Name element N/a\")\n",
    "\n",
    "for i in name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except:\n",
    "        Name.append('--')\n",
    "try:\n",
    "    designation = driver.find_elements_by_xpath('//span[@class=\"ellipsis clr\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Designation element N/a\")\n",
    "\n",
    "for i in designation:\n",
    "    try:\n",
    "        Designation.append(i.text)\n",
    "    except:\n",
    "        Designation.append('--')\n",
    "try:\n",
    "    company = driver.find_elements_by_xpath('//p[@class=\"highlightable\"]/a[2]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Company element N/a\")\n",
    "\n",
    "for i in company:\n",
    "    try:\n",
    "        Company.append(i.text)\n",
    "    except:\n",
    "        Company.append('--')\n",
    "try:\n",
    "    skill = driver.find_elements_by_xpath('//div[@class=\"hireSec highlightable\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Skill element N/a\")\n",
    "\n",
    "for i in skill:\n",
    "    try:\n",
    "        Skills_they_hire_for.append(i.text)\n",
    "    except:\n",
    "        Skills_they_hire_for.append('--')\n",
    "try:\n",
    "    loc = driver.find_elements_by_xpath('//p[@class=\"highlightable\"]/span[2]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Location element N/a\")\n",
    "\n",
    "for i in loc:\n",
    "    try:\n",
    "        Location.append(i.text)\n",
    "    except NoSuchElementException:        \n",
    "        Location.append(\"---\")\n",
    "# Let's check the length of the scrape data\n",
    "print(len(Name),len(Designation),len(Company),len(Skills_they_hire_for),len(Location))\n",
    "\n",
    "\n",
    "# Let's create the dataframe from the scraped data\n",
    "Data_Science=pd.DataFrame({})\n",
    "Data_Science['Name']=Name[0:45]\n",
    "Data_Science['Designation']=Designation[0:45]\n",
    "Data_Science['Company']=Company[0:45]\n",
    "Data_Science['Skills they Hire for']= Skills_they_hire_for[0:45]\n",
    "Data_Science['Location']=Location[0:45]\n",
    "Data_Science\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7155e978",
   "metadata": {},
   "source": [
    "Q8.Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83939ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Let's activate and load the chrome browser\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Let's open the URL\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Book_Name=[] \n",
    "Author_Name=[] \n",
    "Volumes_Sold=[]\n",
    "Publisher=[] \n",
    "Genre=[]\n",
    "\n",
    "# scrape the data as required\n",
    "try:\n",
    "    book = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Book element N/a\")\n",
    "\n",
    "for i in book:\n",
    "    Book_Name.append(i.text)\n",
    "try:\n",
    "    author = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Author element N/a\")\n",
    "\n",
    "for i in author:\n",
    "    Author_Name.append(i.text)\n",
    "try:\n",
    "    vol = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Volumes element N/a\")\n",
    "\n",
    "for i in vol:\n",
    "    Volumes_Sold.append(i.text)\n",
    "try:\n",
    "    pub = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Publisher element N/a\")\n",
    "\n",
    "for i in pub:\n",
    "    Publisher.append(i.text)\n",
    "try:\n",
    "    gen = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Genre element N/a\")\n",
    "\n",
    "for i in gen:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "# Let's create the dataframe from the scraped data\n",
    "Novel_DF=pd.DataFrame({})\n",
    "Novel_DF['Book Name']=Book_Name\n",
    "Novel_DF['Author Name']= Author_Name\n",
    "Novel_DF['Volumes Sold']=Volumes_Sold\n",
    "Novel_DF['Publisher']=Publisher\n",
    "Novel_DF['Genre']=Genre\n",
    "Novel_DF\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284f404",
   "metadata": {},
   "source": [
    "Q.9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be725a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,919,680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>944,475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>918,585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>275,044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>235,412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>46,901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>57,695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>181,942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>38,034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>216,160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  1,919,680  \n",
       "1    51 min     8.7    944,475  \n",
       "2    44 min     8.2    918,585  \n",
       "3    60 min     7.5    275,044  \n",
       "4    43 min     7.6    235,412  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     46,901  \n",
       "96   50 min     7.8     57,695  \n",
       "97   42 min     8.1    181,942  \n",
       "98   45 min     7.1     38,034  \n",
       "99  572 min     8.6    216,160  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Let's activate and load the chrome browser\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Let's open the URL\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Name=[]\n",
    "Year_Span=[] \n",
    "Genre=[] \n",
    "Run_Time=[] \n",
    "Ratings=[] \n",
    "Votes=[]\n",
    "\n",
    "try:\n",
    "    name = driver.find_elements_by_xpath('//h3[@class=\"lister-item-header\"]/a')\n",
    "except NoSuchElementException:\n",
    "    print(\"Name element N/a\")\n",
    "\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "try:\n",
    "    year = driver.find_elements_by_xpath('//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Year span element N/a\")\n",
    "\n",
    "for i in year:\n",
    "    Year_Span.append(i.text)\n",
    "try:\n",
    "    gen = driver.find_elements_by_xpath('//span[@class=\"genre\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Genre element N/a\")\n",
    "\n",
    "for i in gen:\n",
    "    Genre.append(i.text)\n",
    "try:\n",
    "    runtime = driver.find_elements_by_xpath('//span[@class=\"runtime\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Runtime element N/a\")\n",
    "\n",
    "    \n",
    "for i in runtime:\n",
    "    Run_Time.append(i.text)\n",
    "try:\n",
    "    ratings = driver.find_elements_by_xpath('//div[@class=\"ipl-rating-star small\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Rating element N/a\")\n",
    "\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text)\n",
    "try:\n",
    "    vote = driver.find_elements_by_xpath('//span[@name=\"nv\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Vote element N/a\")\n",
    "\n",
    "for i in vote:\n",
    "    Votes.append(i.text)\n",
    "    \n",
    "# Let's create the dataframe from the scraped data\n",
    "IMDB_DF=pd.DataFrame({})\n",
    "IMDB_DF['Name']=Name\n",
    "IMDB_DF['Year Span']= Year_Span\n",
    "IMDB_DF['Genre']=Genre\n",
    "IMDB_DF['Run Time']= Run_Time\n",
    "IMDB_DF['Ratings']=Ratings\n",
    "IMDB_DF['Votes']=Votes\n",
    "IMDB_DF\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781bdbf7",
   "metadata": {},
   "source": [
    "Q10.Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6b2e7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial Characters</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>6000</td>\n",
       "      <td>7</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Audiology (Standardized)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>226</td>\n",
       "      <td>69</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate, Sequential, Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>REJAFADA</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer</td>\n",
       "      <td>1996</td>\n",
       "      <td>6826</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                         Anonymous Microsoft Web Data   \n",
       "3                                Artificial Characters   \n",
       "4                             Audiology (Standardized)   \n",
       "..                                                 ...   \n",
       "307  Image Recognition Task Execution Times in Mobi...   \n",
       "308                                           REJAFADA   \n",
       "309  Influenza outbreak event prediction via Twitte...   \n",
       "310                      Maternal Health Risk Data Set   \n",
       "311  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                                Data Type                  Task  \\\n",
       "0                           Multivariate        Classification    \n",
       "1                           Multivariate        Classification    \n",
       "2                                          Recommender-Systems    \n",
       "3                           Multivariate        Classification    \n",
       "4                           Multivariate        Classification    \n",
       "..                                    ...                   ...   \n",
       "307  Univariate, Sequential, Time-Series            Regression    \n",
       "308                         Multivariate        Classification    \n",
       "309                         Multivariate        Classification    \n",
       "310                                             Classification    \n",
       "311                           Univariate            Regression    \n",
       "\n",
       "                  Attribute Type No of Instances No of Attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2                   Categorical           37711             294   1998   \n",
       "3    Categorical, Integer, Real            6000               7   1992   \n",
       "4                   Categorical             226              69   1992   \n",
       "..                           ...             ...             ...    ...  \n",
       "307                        Real            4000               2   2020   \n",
       "308                     Integer            1996            6826   2020   \n",
       "309               Integer, Real           75840             525   2020   \n",
       "310                                        1014               7   2020   \n",
       "311                        Real            4000               2   2021   \n",
       "\n",
       "[312 rows x 7 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's activate and load the chrome browser\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Let's open the URL\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's navigate to view all dataset\n",
    "try:\n",
    "    dataset=driver.find_element_by_xpath(\"//span[@class='normal']/b/a\")\n",
    "    driver.get(dataset.get_attribute('href'))\n",
    "except NoSuchElementException:\n",
    "    print(\"Span class normal not avlbl\")\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Dataset_Name=[] \n",
    "Data_Type=[]\n",
    "Task=[] \n",
    "Attribute_Type=[] \n",
    "No_of_Instances=[] \n",
    "No_of_Attribute=[] \n",
    "Year=[]\n",
    "try:\n",
    "    name = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td/table/tbody/tr/td[2]/p/b/a')\n",
    "except NoSuchElementException:\n",
    "    print(\"Name element N/a\")\n",
    "\n",
    "for i in name:\n",
    "    Dataset_Name.append(i.text)\n",
    "try:\n",
    "    names = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td/table/tbody/tr/td[2]/p/b/a')\n",
    "except NoSuchElementException:\n",
    "    print(\"Names element N/a\")\n",
    "\n",
    "for i in names:\n",
    "    Dataset_Name.append(i.text)\n",
    "\n",
    "try:\n",
    "    datatype = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[2]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Data Type element N/a\")\n",
    "\n",
    "for i in datatype:\n",
    "    Data_Type.append(i.text)\n",
    "\n",
    "try:\n",
    "    task = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[3]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Task element N/a\")\n",
    "\n",
    "for i in task:\n",
    "    Task.append(i.text)\n",
    "\n",
    "try:    \n",
    "    att = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[4]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Attribute element N/a\")\n",
    "\n",
    "for i in att:\n",
    "    Attribute_Type.append(i.text)\n",
    "\n",
    "try:    \n",
    "    ins = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[5]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Instances element N/a\")\n",
    "    \n",
    "for i in ins:\n",
    "    No_of_Instances.append(i.text)\n",
    "\n",
    "try:    \n",
    "    no_of_att = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[6]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Attribute element N/a\")\n",
    "    \n",
    "for i in no_of_att:\n",
    "    No_of_Attribute.append(i.text)\n",
    "\n",
    "try:\n",
    "    year = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[7]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Year element N/a\")\n",
    "\n",
    "for i in year:\n",
    "    Year.append(i.text)\n",
    "\n",
    "try:\n",
    "    datatype = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[2]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Datatype element N/a\")\n",
    "\n",
    "for i in datatype:\n",
    "    Data_Type.append(i.text)\n",
    "\n",
    "try:\n",
    "    tsk = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[3]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Task element N/a\")\n",
    "\n",
    "for i in tsk:\n",
    "    Task.append(i.text)\n",
    "try:\n",
    "    attr = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[4]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Attribute element N/a\")\n",
    "\n",
    "for i in attr:\n",
    "    Attribute_Type.append(i.text)\n",
    "try:\n",
    "    noi = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[5]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Instance element N/a\")\n",
    "\n",
    "for i in noi:\n",
    "    No_of_Instances.append(i.text)\n",
    "try:\n",
    "    noa = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[6]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Number of Attribute element N/a\")\n",
    "\n",
    "for i in noa:\n",
    "    No_of_Attribute.append(i.text)\n",
    "try:\n",
    "    yr = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[7]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Year element N/a\")\n",
    "\n",
    "for i in yr:\n",
    "    Year.append(i.text)\n",
    "    \n",
    "# Let's create the dataframe from the scraped data\n",
    "UCI_DF=pd.DataFrame({})\n",
    "UCI_DF['Dataset Name']=Dataset_Name \n",
    "UCI_DF['Data Type']=Data_Type\n",
    "UCI_DF['Task']=Task\n",
    "UCI_DF['Attribute Type']=Attribute_Type\n",
    "UCI_DF['No of Instances']=No_of_Instances\n",
    "UCI_DF['No of Attribute']= No_of_Attribute\n",
    "UCI_DF['Year']=Year\n",
    "UCI_DF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
